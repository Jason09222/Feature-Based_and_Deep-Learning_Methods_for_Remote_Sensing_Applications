{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHyCHKCXjt2h",
        "outputId": "a04b55c6-9234-4c84-e406-ccbf9016d45b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!cp -r /content/drive/MyDrive/COMP9517_ZXCZH /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "PS7JpoXWkTCC",
        "outputId": "b1e7e4e6-1e69-4eb9-f5d5-65d771fe1f02"
      },
      "outputs": [],
      "source": [
        "!pip install efficientnet_pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "G4dJwNgDjwtQ",
        "outputId": "583f2de5-993d-48db-b9a2-d1e304f838da"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "<ipython-input-2-83b23bf0b137>:50: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded pretrained weights for efficientnet-b0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/10:   0%|          | 0/150 [00:00<?, ?batch/s]<ipython-input-2-83b23bf0b137>:63: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "Epoch 1/10: 100%|██████████| 150/150 [01:11<00:00,  2.10batch/s, loss=0.666, acc=84.0%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Acc: 95.4%\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/10: 100%|██████████| 150/150 [01:08<00:00,  2.18batch/s, loss=0.138, acc=95.7%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Acc: 96.7%\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/10: 100%|██████████| 150/150 [01:08<00:00,  2.20batch/s, loss=0.090, acc=97.3%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Acc: 97.2%\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/10: 100%|██████████| 150/150 [01:09<00:00,  2.17batch/s, loss=0.067, acc=97.9%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Acc: 97.6%\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/10: 100%|██████████| 150/150 [01:09<00:00,  2.15batch/s, loss=0.057, acc=98.2%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Acc: 97.4%\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6/10: 100%|██████████| 150/150 [01:10<00:00,  2.13batch/s, loss=0.047, acc=98.4%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Acc: 97.7%\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7/10: 100%|██████████| 150/150 [01:09<00:00,  2.16batch/s, loss=0.044, acc=98.5%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Acc: 96.6%\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8/10: 100%|██████████| 150/150 [01:11<00:00,  2.11batch/s, loss=0.035, acc=99.0%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Acc: 97.5%\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9/10: 100%|██████████| 150/150 [01:09<00:00,  2.16batch/s, loss=0.032, acc=99.1%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Acc: 97.4%\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10/10: 100%|██████████| 150/150 [01:13<00:00,  2.05batch/s, loss=0.030, acc=99.1%]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Acc: 97.2%\n",
            "--------------------------------------------------\n",
            "\n",
            "Training accuracy: 99.1% | Verification accuracy: 97.2%\n",
            "Normal training\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from efficientnet_pytorch import EfficientNet\n",
        "from tqdm import tqdm\n",
        "\n",
        "# device layout\n",
        "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "# dataset allocation\n",
        "train_dir = '/content/COMP9517_ZXCZH/train'\n",
        "test_dir = '/content/COMP9517_ZXCZH/test'\n",
        "\n",
        "# Data enhancement pipeline\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.RandomCrop(224),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# data loading\n",
        "train_dataset = datasets.ImageFolder(train_dir, transform=train_transforms)\n",
        "test_dataset = datasets.ImageFolder(test_dir, transform=test_transforms)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4, pin_memory=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, num_workers=4, pin_memory=True)\n",
        "\n",
        "# Model initialization\n",
        "model = EfficientNet.from_pretrained('efficientnet-b0', num_classes=15)\n",
        "model.to(device)\n",
        "\n",
        "# Training configuration\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=3e-4)\n",
        "\n",
        "# Initialize GradScaler before the training loop\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "for epoch in range(10):\n",
        "    model.train()\n",
        "    train_loss, correct, total = 0, 0, 0\n",
        "    with tqdm(train_loader, unit=\"batch\") as pbar:\n",
        "        pbar.set_description(f\"Epoch {epoch+1}/10\")\n",
        "        for images, labels in pbar:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Enable automatic mixing precision context\n",
        "            with torch.cuda.amp.autocast():\n",
        "                outputs = model(images)       # FP16/FP32 is automatically selected\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "            # Scale the gradient and backpropagate\n",
        "            scaler.scale(loss).backward()\n",
        "\n",
        "            # Update parameters (automatic unscale gradient)\n",
        "            scaler.step(optimizer)\n",
        "\n",
        "            # Update the pantograph status\n",
        "            scaler.update()\n",
        "\n",
        "            # statistical information\n",
        "            train_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            pbar.set_postfix({\n",
        "                \"loss\": f\"{train_loss/(total//64):.3f}\",\n",
        "                \"acc\": f\"{100*correct/total:.1f}%\"\n",
        "            })\n",
        "\n",
        "    # verification stage\n",
        "    model.eval()\n",
        "    val_correct, val_total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            val_total += labels.size(0)\n",
        "            val_correct += (predicted == labels).sum().item()\n",
        "\n",
        "    # Print the epoch summary\n",
        "    print(f\"Val Acc: {100*val_correct/val_total:.1f}%\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "# Overfitting judgment\n",
        "final_train_acc = 100 * correct / total\n",
        "final_val_acc = 100 * val_correct / val_total\n",
        "print(f\"\\nTraining accuracy: {final_train_acc:.1f}% | Verification accuracy: {final_val_acc:.1f}%\")\n",
        "if final_train_acc - final_val_acc > 10:\n",
        "    print(\"Overfitting detected!\")\n",
        "else:\n",
        "    print(\"Normal training\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "zM21FYyWnaiZ",
        "outputId": "3f60d6b2-cfd8-49fe-b2c5-5975fdd049de"
      },
      "outputs": [],
      "source": [
        "!pip install grad-cam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6BWtIMt0m0RC"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import random\n",
        "\n",
        "from pytorch_grad_cam import GradCAM\n",
        "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
        "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
        "\n",
        "# The last convolutional layer in EfficientNet is usually model._blocks[-1]._project_conv\n",
        "target_layers = [model._blocks[-1]._project_conv]\n",
        "\n",
        "# Get class names and image paths\n",
        "class_names = train_dataset.classes\n",
        "image_paths, labels = zip(*test_dataset.samples)\n",
        "\n",
        "for class_idx, class_name in enumerate(class_names):\n",
        "    print(f\"Grad-CAM for {class_name}...\")\n",
        "\n",
        "    # Get all image paths for the current class\n",
        "    class_image_paths = [path for path, label in zip(image_paths, labels) if label == class_idx]\n",
        "    if not class_image_paths:\n",
        "        print(f\"No images found for class {class_name}\")\n",
        "        continue\n",
        "\n",
        "    # Randomly select one image\n",
        "    img_path = random.choice(class_image_paths)\n",
        "    pil_img = Image.open(img_path).convert(\"RGB\")\n",
        "    input_tensor = test_transforms(pil_img).unsqueeze(0).to(device)\n",
        "\n",
        "    # Get model prediction for the image\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        output = model(input_tensor)\n",
        "        pred_class = output.argmax(dim=1).item()\n",
        "\n",
        "    # Instantiate Grad-CAM and generate heatmap\n",
        "    cam = GradCAM(model=model, target_layers=target_layers)\n",
        "    grayscale_cam = cam(input_tensor=input_tensor, targets=[ClassifierOutputTarget(pred_class)])[0]\n",
        "\n",
        "    # Convert input image to numpy format for overlaying heatmap\n",
        "    img_np = np.array(pil_img.resize((224, 224))) / 255.0\n",
        "    visualization = show_cam_on_image(img_np, grayscale_cam, use_rgb=True)\n",
        "\n",
        "    # Display results\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.title(f\"Original - Label: {class_name}\")\n",
        "    plt.imshow(img_np)\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.title(f\"Grad-CAM - Predicted: {class_names[pred_class]}\")\n",
        "    plt.imshow(visualization)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Output the samples of each class about the explanable images\n",
        "Already hide the outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "qIyDMhqtj-gQ",
        "outputId": "f1d3e79f-72c6-470b-e785-f291aea404a9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ImageFilter\n",
        "import random\n",
        "import torch\n",
        "from pytorch_grad_cam import GradCAM\n",
        "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
        "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
        "\n",
        "# Last convolutional layer in EfficientNet\n",
        "target_layers = [model._blocks[-1]._project_conv]\n",
        "class_names = train_dataset.classes\n",
        "image_paths, labels = zip(*test_dataset.samples)\n",
        "\n",
        "def add_noise(img_np, mean=0, std=0.1):\n",
        "    noise = np.random.normal(mean, std, img_np.shape)\n",
        "    noisy_img = np.clip(img_np + noise, 0, 1)\n",
        "    return noisy_img\n",
        "\n",
        "def add_blur(pil_img):\n",
        "    return pil_img.filter(ImageFilter.GaussianBlur(radius=4))\n",
        "\n",
        "def add_occlusion(img_np, box_size=50):\n",
        "    h, w, _ = img_np.shape\n",
        "    x = random.randint(0, w - box_size)\n",
        "    y = random.randint(0, h - box_size)\n",
        "    img_np[y:y+box_size, x:x+box_size, :] = 0\n",
        "    return img_np\n",
        "\n",
        "# Show one image per class\n",
        "for class_idx, class_name in enumerate(class_names):\n",
        "    print(f\"Grad-CAM for {class_name}...\")\n",
        "\n",
        "    class_image_paths = [path for path, label in zip(image_paths, labels) if label == class_idx]\n",
        "    if not class_image_paths:\n",
        "        print(f\"No images found for class {class_name}\")\n",
        "        continue\n",
        "\n",
        "    # Select one random image\n",
        "    img_path = random.choice(class_image_paths)\n",
        "    pil_img = Image.open(img_path).convert(\"RGB\")\n",
        "    original_img = pil_img.resize((224, 224))\n",
        "    original_np = np.array(original_img) / 255.0\n",
        "\n",
        "    # Generate three perturbed versions\n",
        "    noisy_np = add_noise(np.copy(original_np))\n",
        "    noisy_img = Image.fromarray((noisy_np * 255).astype(np.uint8))\n",
        "\n",
        "    blurred_img = add_blur(original_img)\n",
        "    blurred_np = np.array(blurred_img) / 255.0\n",
        "\n",
        "    occluded_np = add_occlusion(np.copy(original_np))\n",
        "    occluded_img = Image.fromarray((occluded_np * 255).astype(np.uint8))\n",
        "\n",
        "    # Collect all versions in a list\n",
        "    versions = [\n",
        "        (\"Original\", original_np, original_img),\n",
        "        (\"Noisy\", noisy_np, noisy_img),\n",
        "        (\"Blurred\", blurred_np, blurred_img),\n",
        "        (\"Occluded\", occluded_np, occluded_img)\n",
        "    ]\n",
        "\n",
        "    cam = GradCAM(model=model, target_layers=target_layers)\n",
        "\n",
        "    plt.figure(figsize=(16, 8))\n",
        "    for i, (title, img_np, img_pil) in enumerate(versions):\n",
        "        input_tensor = test_transforms(img_pil).unsqueeze(0).to(device)\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            output = model(input_tensor)\n",
        "            pred_class = output.argmax(dim=1).item()\n",
        "\n",
        "        grayscale_cam = cam(input_tensor=input_tensor, targets=[ClassifierOutputTarget(pred_class)])[0]\n",
        "        cam_result = show_cam_on_image(img_np, grayscale_cam, use_rgb=True)\n",
        "\n",
        "        # Display original or perturbed image\n",
        "        plt.subplot(2, 4, i + 1)\n",
        "        plt.title(f\"{title} Image\")\n",
        "        plt.imshow(img_np)\n",
        "        plt.axis('off')\n",
        "\n",
        "        # Display heatmap\n",
        "        plt.subplot(2, 4, i + 5)\n",
        "        plt.title(f\"{title} Grad-CAM\\nPred: {class_names[pred_class]}\")\n",
        "        plt.imshow(cam_result)\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
